{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_map = pd.read_csv('id_map.csv')\n",
    "# sort id_map by ID column\n",
    "id_map = id_map.sort_values(by=['ID'], ascending=True)\n",
    "id_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('SampleSubmission.csv')\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images\n",
    "\n",
    "train_h5=  \"train_data.h5\" \n",
    "test_h5 = \"test_data.h5\"\n",
    "\n",
    "\n",
    "# Open the HDF5 file\n",
    "with h5py.File(train_h5, 'r') as hdf:\n",
    "    # Extract the images (X)\n",
    "    train_data = np.array(hdf['images'])\n",
    "    \n",
    "    # Extract the labels (y)\n",
    "    train_label = np.array(hdf['labels'])\n",
    "\n",
    "\n",
    "with h5py.File(test_h5, 'r') as hdf:\n",
    "    # Extract the images (X)\n",
    "    test_data = np.array(hdf['images'])\n",
    "\n",
    "print(f\"Shape of train_data {train_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering Version 1 - For Statistics from raw image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to extract statistics \n",
    "class Version_1_FE(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features=None):\n",
    "        if features is None:\n",
    "            self.features = {\n",
    "                'mean': np.mean,\n",
    "                'median': np.median,\n",
    "                'std': np.std,\n",
    "                'min': np.min,\n",
    "                'max': np.max,\n",
    "            }\n",
    "        else:\n",
    "            self.features = features\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        num_samples, height, width, num_channels = X.shape\n",
    "        output = np.zeros((num_samples, num_channels * len(self.features)))\n",
    "\n",
    "        for i, sample in tqdm(enumerate(X), total=num_samples, desc=\"Processing samples\"):\n",
    "            feature_vector = []\n",
    "            for channel in range(num_channels):\n",
    "                # rather than extract the full data, extract a patch of size (8 * 8)\n",
    "                patch_size = 8\n",
    "                center_row, center_col= 16//2, 16//2 \n",
    "                start_row = patch_size - center_row//2\n",
    "                end_row = patch_size + center_row//2 + 1\n",
    "                start_col = patch_size - center_col// 2\n",
    "                end_col = patch_size + center_col//2 + 1\n",
    "\n",
    "                channel_data = sample[start_row:end_row, start_col:end_col, channel]\n",
    "\n",
    "                for feature_name, feature_func in self.features.items():\n",
    "                    feature_value = feature_func(channel_data)\n",
    "                    feature_vector.append(feature_value)\n",
    "            output[i] = feature_vector\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appply version_1 feature engineering to train dataset\n",
    "scf = Version_1_FE()\n",
    "train_version_1_data = scf.transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appply version_1 feature engineering to test dataset\n",
    "scf = Version_1_FE()\n",
    "test_version_1_data = scf.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bands naming dictionary\n",
    "bands_dict = {0: 'Blue',\n",
    "1: 'Green',\n",
    "2: 'Red',\n",
    "3: 'NIR',\n",
    "4: 'SWIR1',\n",
    "5: 'SWIR2',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN\n",
    "# create a column for each of the features created for train\n",
    "col = [f\"{bands_dict[i]}_{feature}\" for i in range(train_data.shape[3]) for feature in scf.features.keys()]\n",
    "train_dataframe = pd.DataFrame(train_version_1_data, columns=col)\n",
    "train_dataframe[\"class\"] = train_label\n",
    "train_dataframe['id'] = ['id_' + str(i) for i in range(train_data.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "# create a column for each of the features created for test\n",
    "col = [f\"{bands_dict[i]}_{feature}\" for i in range(test_data.shape[3]) for feature in scf.features.keys()]\n",
    "test_dataframe = pd.DataFrame(test_version_1_data, columns=col)\n",
    "test_dataframe['id'] = id_map['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_needed_cols = ['id', 'class', 'fold']\n",
    "train_columns =  [col for col in train_dataframe.columns if col not in not_needed_cols]\n",
    "print(train_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgkf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "for i, (train_index, test_index) in enumerate(sgkf.split(train_dataframe[\"id\"].values, train_dataframe[\"class\"].values)):\n",
    "    train_dataframe.loc[test_index, \"fold\"] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "auc_score = 0\n",
    "fold = 5\n",
    "test_predictions = []\n",
    "\n",
    "\n",
    "for i in range(fold):\n",
    "    train = train_dataframe[train_dataframe['fold']!= i]\n",
    "    val = train_dataframe[train_dataframe['fold']== i]\n",
    "\n",
    "\n",
    "    X_train = train[train_columns]\n",
    "    y_train = train['class']\n",
    "\n",
    "    X_test = val[train_columns]\n",
    "    y_test =  val['class']\n",
    "\n",
    "    train_sample_weights = compute_sample_weight(class_weight=\"balanced\", y=y_train)\n",
    "\n",
    "    train_data = lgb.Dataset(\n",
    "        X_train,\n",
    "        label=y_train,\n",
    "        weight=train_sample_weights,\n",
    "    )\n",
    "\n",
    "    validation_sample_weights = compute_sample_weight(\n",
    "        class_weight=\"balanced\",\n",
    "        y=y_test,\n",
    "    )\n",
    "\n",
    "    validation_data = lgb.Dataset(X_test, label=y_test, weight=validation_sample_weights)\n",
    "\n",
    "    param  = {\n",
    "   'n_estimators':2500,'objective': 'binary',\n",
    "    'learning_rate':0.03, 'num_leaves':15,'reg_alpha':1,'reg_lambda':7,\n",
    "    'max_depth':9,\n",
    "    'random_state':42,'verbose': -1,\n",
    "     \"num_class\": 1\n",
    "     }\n",
    "\n",
    "\n",
    "    num_round = 5000\n",
    "    early_stopping_rounds = 100\n",
    "\n",
    "    model = lgb.train(\n",
    "        param,\n",
    "        train_data,\n",
    "        num_round,\n",
    "        valid_sets=[validation_data],\n",
    "        callbacks=[lgb.early_stopping(stopping_rounds=early_stopping_rounds)],\n",
    "    )\n",
    "\n",
    "    pred_prob = model.predict(X_test)\n",
    "\n",
    "    # evaluation of model\n",
    "    auc_score += roc_auc_score(y_test, pred_prob)\n",
    "    print(\" \")\n",
    "    print(f'AUC for fold {i+1}: {roc_auc_score(y_test, pred_prob)}')\n",
    "    print(\" \")\n",
    "\n",
    "    # test prediction\n",
    "    test_preds = model.predict(test_dataframe[train_columns])\n",
    "    test_predictions.append(test_preds)\n",
    "\n",
    "\n",
    "print(f'CV Log_loss: {auc_score/fold}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate mean predictions for test dataset\n",
    "mean_test_preds = np.mean(test_predictions, axis=0)\n",
    "test_dataframe['class'] = mean_test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with submission file\n",
    "\n",
    "merged_submmission = sub[['id']].merge(test_dataframe, on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_submmission[['id', 'class']].to_csv('second_sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb.plot_importance(model, importance_type='gain', figsize=(20, 10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-machine-learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
